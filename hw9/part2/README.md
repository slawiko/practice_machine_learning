### t-SNE MNIST

Данные качал при помощи `sklearn.datasets.fetch_mldata`. Визуализирова только рандомные 10000 элементов из выборки, в угоду скорости. Далее осуществлял перебор параметров: `perplexity` 10, 30, 50, количество итераций 250, 500, 1000, 3000. `learning_rate(epsion)` не перебирал, использовал 500, как в примере на сайте [t-SNE](https://lvdmaaten.github.io/tsne/).

Как понятно из графиков [p=10 iterations=250](./plots/p=10_iterations=250.png), [p=30 iterations=250](./plots/p=30_iterations=250.png), [p=50 iterations=250](./plots/p=50_iterations=250.png) 250 итераций довольно мало. Притом не важно какое perplexity. Не зря это минимальное значение для t-SNE.

А на ![p=10 iterations=500](./plots/p=10_iterations=500.png) уже можно придумать какие-то зависимости. Например `4` и `9` смешались, что можно объяснить тем, что цифры часто похожи. Но больше никаких зависимостей на этой картинке я не увидел